{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f52a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc502e",
   "metadata": {},
   "source": [
    "CartPole Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec4b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1', new_step_api=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcc3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_state = env.observation_space\n",
    "action_space = env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ddf89",
   "metadata": {},
   "source": [
    "Observation space represents a 1 dimentional array with 4 discrete variables corresponding to the cart position (0), cart velocity (1), pole angle (2), and pole angular velocity (3) respectively. The action space represents another 1 dimensional array with all the possible actions that can be taken. There are only two actions: push cart to the left (0) and push cart to the right (1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974f6cd",
   "metadata": {},
   "source": [
    "Before implementing the SARSA algorithm, we created a block of code which randomly samples an action from the action space. This will serve as a baseline which we can compare against our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb5f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_results = []\n",
    "steps = 0\n",
    "for n in range(500):\n",
    "    steps += 1\n",
    "    state = env.reset()\n",
    "    action = action_space.sample()\n",
    "    state, reward, end, _, info = env.step(action)\n",
    "    if end:\n",
    "        random_results.append(steps)\n",
    "        steps = 0\n",
    "        env.reset()\n",
    "env.close()\n",
    "print(sum(random_results) / len(random_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563b1075",
   "metadata": {},
   "source": [
    "SARSA EpsGreedyQ Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9210856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "lr_rate = 0.05\n",
    "discount = 0.95\n",
    "episodes = 100000\n",
    "max_steps = 500\n",
    "\n",
    "# Epsilon Greedy Search Parameters\n",
    "epsilon = 1.0 \n",
    "min_epsilon = 0.1 \n",
    "decay_rate = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e345707",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros((obs_state.shape[0], action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d607b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a2bb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy_action(state): \n",
    "    action = 0\n",
    "    if np.random.uniform() < epsilon:\n",
    "        # Number lower than epsilon means explore\n",
    "        action = random.randint(0,1)\n",
    "    else:\n",
    "        # Higher number than epsilon means use prior knowledge\n",
    "        action = np.argmax(Q[state, :])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993efe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    step = 0\n",
    "    state1 = env.reset()\n",
    "    done = False\n",
    "    action1 = eps_greedy_action(state1)\n",
    "    for step in range(max_steps):\n",
    "        state2, reward, end, _, info = env.step(action1)\n",
    "        action2 = eps_greedy_action(state2)\n",
    "        Q[state1][action1] = Q[state1][action1] + lr_rate * (reward + discount * (Q[state2][action2]) - Q[state1][action1])\n",
    "        state1 = state2\n",
    "        action1 = action2\n",
    "        if end:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b79ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    rewards = []\n",
    "    for n in range(episodes):\n",
    "        step = 0\n",
    "        state1 = env.reset()\n",
    "        done = False\n",
    "        ep_reward = 0\n",
    "        for step in range(max_steps):\n",
    "            action = np.argmax(Q[state1, :])\n",
    "            state2, reward, end, _, info = env.step(action)\n",
    "            ep_reward += reward\n",
    "            state1 = state2\n",
    "            if end:\n",
    "                break\n",
    "        rewards.append(ep_reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a97ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3c1d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
